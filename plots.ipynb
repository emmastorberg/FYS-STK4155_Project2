{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from plotting import *\n",
    "from GradientDescent import Plain, Stochastic\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "degree = 2\n",
    "x = np.linspace(0, 1, n)\n",
    "\n",
    "X = np.empty((n, degree+1))\n",
    "X[:,0] = 1\n",
    "X[:,1] = x\n",
    "X[:,2] = x**2\n",
    "\n",
    "y =  3 + 7*x + 5*x**2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[:,1:] = scaler.fit_transform(X_train[:,1:])\n",
    "X_test[:,1:] = scaler.transform(X_test[:,1:])\n",
    "\n",
    "analytic_beta = [utils.analytic_beta_OLS(X_train, y_train)]\n",
    "\n",
    "beta = np.ones(degree+1) * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "max_iter = 2000\n",
    "\n",
    "analytic_solution = [utils.cost_OLS(X_test, analytic_beta, y_test)] * max_iter\n",
    "\n",
    "plain_w_momentum = Plain(lr=lr, max_iter=max_iter, momentum=0.5, save_info_per_iter=True)\n",
    "plain_wo_momentum = Plain(lr=lr, max_iter=max_iter, momentum=0.0, save_info_per_iter=True)\n",
    "\n",
    "plain_w_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "plain_wo_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "\n",
    "plain_w_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "plain_wo_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "\n",
    "plain_info_w_momentum = plain_w_momentum.info\n",
    "plain_info_wo_momentum = plain_wo_momentum.info\n",
    "\n",
    "plain_iter_range = np.arange(1, max_iter+1)\n",
    "\n",
    "plain_mse = [0] * max_iter\n",
    "plain_mse_mom = [0] * max_iter\n",
    "\n",
    "for i in range(max_iter):\n",
    "    plain_mse[i] = utils.cost_OLS(X_test, [plain_info_wo_momentum[i]], y_test)\n",
    "    plain_mse_mom[i] = utils.cost_OLS(X_test, [plain_info_w_momentum[i]], y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_func_of_epochs(\n",
    "    epochs=plain_iter_range,\n",
    "    mse=plain_mse,\n",
    "    mse_mom=plain_mse_mom,\n",
    "    analytical=analytic_solution,\n",
    "    fixed_lr=lr,\n",
    "    sgd=False,\n",
    "    filename=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "\n",
    "analytic_solution = [utils.cost_OLS(X_test, analytic_beta, y_test)] * n_epochs\n",
    "\n",
    "stochastic_w_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.9, lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "stochastic_wo_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.0, lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "\n",
    "stochastic_w_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "stochastic_wo_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "\n",
    "stochastic_w_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "stochastic_wo_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "\n",
    "sgd_info_w_momentum = stochastic_w_momentum.info\n",
    "sgd_info_wo_momentum = stochastic_wo_momentum.info\n",
    "\n",
    "sgd_iter_range = np.arange(1, n_epochs+1)\n",
    "\n",
    "sgd_mse = [0] * n_epochs\n",
    "sgd_mse_mom = [0] * n_epochs\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    sgd_mse[i] = utils.cost_OLS(X_test, [sgd_info_wo_momentum[i]], y_test)\n",
    "    sgd_mse_mom[i] = utils.cost_OLS(X_test, [sgd_info_w_momentum[i]], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_func_of_epochs(\n",
    "    epochs=sgd_iter_range,\n",
    "    mse=sgd_mse,\n",
    "    mse_mom=sgd_mse_mom,\n",
    "    analytical=analytic_solution,\n",
    "    fixed_lr=lr,\n",
    "    sgd=True,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "\n",
    "stochastic_w_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.9, lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "stochastic_wo_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.0, lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "adagrad_w_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.9, tuner=\"adagrad\", lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "adagrad_wo_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.0, tuner=\"adagrad\", lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "rmsprop_w_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.9, tuner=\"rmsprop\", lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "rmsprop_wo_momentum = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.0, tuner=\"rmsprop\", lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "adam = Stochastic(lr=lr, M=2, n_epochs=n_epochs, momentum=0.0, tuner=\"adam\", lr_schedule=\"linear\", save_info_per_iter=True)\n",
    "\n",
    "stochastic_w_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "stochastic_wo_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "adagrad_w_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "adagrad_wo_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "rmsprop_w_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "rmsprop_wo_momentum.set_gradient(utils.analytic_grad_OLS)\n",
    "adam.set_gradient(utils.analytic_grad_OLS)\n",
    "\n",
    "stochastic_w_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "stochastic_wo_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "adagrad_w_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "adagrad_wo_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "rmsprop_w_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "rmsprop_wo_momentum.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "adam.gradient_descent(X_train, [np.copy(beta)], y_train)\n",
    "\n",
    "sgd_info_w_momentum = stochastic_w_momentum.info\n",
    "sgd_info_wo_momentum = stochastic_wo_momentum.info\n",
    "adagrad_info_w_momentum = adagrad_w_momentum.info\n",
    "adagrad_info_wo_momentum = adagrad_wo_momentum.info\n",
    "rmsprop_info_w_momentum = adagrad_w_momentum.info\n",
    "rmsprop_info_wo_momentum = adagrad_wo_momentum.info\n",
    "adam_info = adagrad_w_momentum.info\n",
    "\n",
    "iter_range = np.arange(1, n_epochs+1)\n",
    "\n",
    "sgd_mse = [0] * n_epochs\n",
    "sgd_mse_mom = [0] * n_epochs\n",
    "adagrad_mse = [0] * n_epochs\n",
    "adagrad_mse_mom = [0] * n_epochs\n",
    "rmsprop_mse = [0] * n_epochs\n",
    "rmsprop_mse_mom = [0] * n_epochs\n",
    "adam_mse = [0] * n_epochs\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    sgd_mse[i] = utils.cost_OLS(X_test, [sgd_info_wo_momentum[i]], y_test)\n",
    "    sgd_mse_mom[i] = utils.cost_OLS(X_test, [sgd_info_w_momentum[i]], y_test)\n",
    "    adagrad_mse[i] = utils.cost_OLS(X_test, [adagrad_info_wo_momentum[i]], y_test)\n",
    "    adagrad_mse_mom[i] = utils.cost_OLS(X_test, [adagrad_info_w_momentum[i]], y_test)\n",
    "    rmsprop_mse[i] = utils.cost_OLS(X_test, [rmsprop_info_wo_momentum[i]], y_test)\n",
    "    rmsprop_mse_mom[i] = utils.cost_OLS(X_test, [rmsprop_info_w_momentum[i]], y_test)\n",
    "    adam_mse[i] = utils.cost_OLS(X_test, [adam_info[i]], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_stacked_subplots(\n",
    "    epochs=sgd_iter_range,\n",
    "    sgd=sgd_mse,\n",
    "    sgd_mom=sgd_mse_mom,\n",
    "    adagrad=adagrad_mse,\n",
    "    adagrad_mom=adagrad_mse_mom,\n",
    "    rms=rmsprop_mse,\n",
    "    rms_mom=rmsprop_mse_mom,\n",
    "    adam=adam_mse,\n",
    "    lr=lr,\n",
    "    plot_lr=False,\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
