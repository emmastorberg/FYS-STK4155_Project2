\begin{adjustwidth}{2cm}{2cm} % Adjust the margins: {left margin}{right margin}
        % \textcolor{cyan}{
        % \begin{itemize}
        %     \item Provide a short introduction to the topic and why it's important
        %     \item Introduce a challenge or unresolved issue with the topic (that you will try to solve)
        %     \item Describe what you have done to solve this
        %     \item State the main results
        %     \item Outline the implications
        % \end{itemize}}
    Neural networks are highly topical at the moment, both in popular science and academic circles, with a wide range of uses across many disciplines. One area where neural networks can make a big impact is in diagnostic aid for medical professionals. However, there are challenges related to the implementation of neural networks, both in terms of their creation and interpretation. In this project, we build a neural network from scratch to predict instances of breast cancer in the Wisconsin Breast Cancer (Diagnostic) Dataset \cite{sklearnBreastCancerData}. This is done step by step, beginning by implementing a variety of gradient descent techniques as standalone methods for determining optimal parameters in linear regression. These methods are thereafter implemented for use in the training of our neural networks. We tested them for two distinct tasks. First, we contrasted them with linear regression techniques for prediction of numerical values from a second-degree polynomial, followed by a binary classification task, which we compare to logistic regression. The performance of our gradient descent methods alone aligned decently with the theory, with the momentum-based methods in particular performing well. We were able to train a network to predict polynomial data with an MSE as low as 2.5 after 10 epochs, albeit not as well as linear regression (especially OLS), which was virtually indistinguishable from the exact solution. When it came to classification, however, we saw strange behavior with our own implementation, with the model performing well on smaller multiclass datasets, but not being able to predict breast cancer data. We continued our analysis with a neural network implemented with PyTorch instead, and found that the best model was \textcolor{red}{(best model described here)}. We conclude that neural networks are a useful tool for some problems, but not all. We must be wary of their drawbacks and shortcomings before choosing to use them in real-world (especially medical) contexts.
      \end{adjustwidth}

% PROJECT 1 ABSTRACT FOR COMPARISON:
% Understanding the intricacies of machine learning is an essential part of navigating our data-driven world. In this project, we explored various methods for solving linear regression on the 2D Franke function \cite{franke} and a dataset from the United States Geological Survey \cite{usgovterraindata}. Our analysis focused on Ordinary Least Squares (OLS), ridge regression and LASSO regression, evaluated through statistical metrics such as the mean squared error and R$^2$ score. Additionally, we used resampling methods like bootstrap resampling and $k$-fold cross-validation to achieve more reliable results. We investigated the bias-variance trade-off and challenged our models with the goal of first inducing overfitting, and thereafter combating it using our understanding of the theory and techniques we have learned. Initially, our OLS model performed well, but the introduction of regularization terms revealed an error in our procedure for determining optimal hyperparameters, resulting in unreasonable values despite passing tests against the methods of \lstinline[basicstyle=\small\ttfamily]|scikit-learn|. We emphasize the importance of following sound statistical intuition and employing supplementary methods such as visual inspection when interpreting results, rather than solely relying on numerical metrics.