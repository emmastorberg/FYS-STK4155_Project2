Neural networks are an highly relevant machine learning technique in today's digital era, with a vast range of uses in all kinds of fields. \textcolor{red}{A sentence or two linking real-world use to our project here.} This report will explore some of the fundamental techniques used in the creation and training of neural networks. 

When we make predictions, it is important to have some way of assessing how good they are. This can be done with a cost function, as covered in detail in our previous report \emph{Linear Regression and Basic Resampling Techniques for Modeling 2D Datasets} \cite{fysstkproject1}. We utilized the fact that we can minimize the cost of some choice of model parameters by finding where the derivative of the cost function is 0, and we will make use of the same observation to determine which model parameters to use in our neural network. 

The key difference from our previous approach is this: Rather than determining the optimal model parameters explicitly using derived analytical expressions, we will instead use a numerical method for iterating stepwise closer and closer to the minimum of the cost function. This stepping method is known as \emph{gradient descent}. In this report, we are first considering this process in isolation, and thereafter comparing the results of these numerical techniques to their analytical counterparts. Once we confirm that our gradient descent methods work as intended, we are implementing them as a way of training a neural network.

Our previous work used various linear regression methods for predicting 2D datasets. Using the neural netowrk, we will build on this to predict noisy Franke function data \cite{franke} as an initial test of its prediction capabilities. Afterwards, we will explore another common usage of neural networks, namely classification tasks, and compare its performance to that of logistic regression. For this purpose, we will consider the Wisconsin Breast Cancer dataset \textcolor{red}{(add source here)}, with a goal of predicting the presence of cancer in each patient with as high a degree of accuracy as possible. Finally, we will evaluate how the different methods of regression and classification fare in comparison to one another for different methods of gradient descent.

