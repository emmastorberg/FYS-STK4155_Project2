% \textcolor{cyan}{
%         \begin{itemize}
%             \item Motivate the reader; the first part of the introduction always gives a motivation and tries to present the overarching ideas.
%             \item Outline what we have done.
%             \item Provide the structure of the report and how it is organized, etc.
%         \end{itemize}}

Neural networks are a highly relevant machine learning technique in today's digital era, with a vast range of uses in various fields, from healthcare to finance and beyond. They are increasingly employed in medical diagnostics to analyze complex data patterns and assist in early disease detection, with striking accuracy in preliminary testing \cite{ZELTZER2023480}. This report will explore some of the fundamental techniques used in the creation and training of neural networks, aiming to produce models based on real medical data.

When we make predictions, it is important to have a way of assessing their accuracy. This can be done with a cost function, as covered in detail in our previous report \emph{Linear Regression and Basic Resampling Techniques for Modeling 2D Datasets} \cite{fysstkproject1}. We utilized the fact that we can minimize the cost of some choice of model parameters by finding where the derivative of the cost function is 0, and we will make use of the same observation to determine which model parameters to use in our neural network. The key difference from our previous approach is this: Rather than determining the optimal model parameters explicitly using derived analytical expressions, we will instead use a numerical method to iterate stepwise closer to the minimum of the cost function. This stepping method is known as \emph{gradient descent}. 

In this report, we first consider this process in isolation, and thereafter compare the results of these numerical techniques to their analytical counterparts. Once we confirm that our gradient descent methods work as intended, we will implement them as a way of training a neural network.

Our previous work used various linear regression methods for predicting 2D datasets. Taking a step back from this, we will train the neural network on a dataset generated from a simple second-degree polynomial as an initial test of its numerical prediction capabilities. Afterwards, we will explore another common usage of neural networks, namely classification tasks, and compare their performance to that of logistic regression. For this purpose, we will consider the Wisconsin Breast Cancer dataset \cite{sklearnBreastCancerData}, aiming to predict the presence of cancer in each patient with the highest degree of accuracy possible. Finally, we will evaluate how the different methods of regression and classification fare in comparison to one another across various gradient descent techniques.

